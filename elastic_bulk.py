# elastic_bulk.py
from elasticsearch import Elasticsearch, helpers
import pandas as pd
import json

def get_stock_info():
    base_url = "http://kind.krx.co.kr/corpgeneral/corpList.do"
    method = "download"
    url = f"{base_url}?method={method}"

    df = pd.read_html(url, header=0, encoding='euc-kr')[0]

    # âœ… í•„ìš”í•œ í•„ë“œë§Œ ìœ ì§€
    df = df[['ì¢…ëª©ì½”ë“œ', 'íšŒì‚¬ëª…', 'ì—…ì¢…', 'ì£¼ìš”ì œí’ˆ', 'ìƒì¥ì¼']]

    # âœ… í•„ë“œëª… ì˜ë¬¸í™”
    df.columns = ['stock_code', 'company_name', 'industry', 'main_products', 'listing_date']

    # âœ… ì¢…ëª©ì½”ë“œ 6ìë¦¬ í¬ë§· ì ìš©
    df['stock_code'] = df['stock_code'].apply(lambda x: f"{x:06d}")

    # âœ… Null ê°’ ì²˜ë¦¬ (dropna() ëŒ€ì‹  fillna("N/A") ì‚¬ìš©)
    df = df.fillna("N/A")

    # âœ… ë°ì´í„° ê°œìˆ˜ ë° ìƒ˜í”Œ ì¶œë ¥
    print(f"ğŸ“Œ ë°ì´í„°í”„ë ˆì„ ë¡œë“œ ì™„ë£Œ! ë°ì´í„° ê°œìˆ˜: {len(df)}ê°œ")
    print(df.head())

    return df

# âœ… ë°ì´í„° ë¡œë“œ
df = get_stock_info()

# âœ… ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸ í›„ ì¢…ë£Œ
if df.empty:
    print("âŒ ì˜¤ë¥˜: ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤! ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    exit()

# âœ… JSON ë³€í™˜ (ì—¬ê¸°ì—ì„œ ì´ì „ ì½”ë“œ ëˆ„ë½ ë¬¸ì œ í•´ê²°)
json_records = json.loads(df.to_json(orient='records'))

# âœ… Elasticsearch ì—°ê²°
es = Elasticsearch("http://localhost:9200", http_compress=True)
index_name = 'stock_info_nori_index'

# âœ… ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ í›„ ì¬ìƒì„±
if es.indices.exists(index=index_name):
    print(f"âš ï¸ ê¸°ì¡´ ì¸ë±ìŠ¤ '{index_name}' ì‚­ì œ ì¤‘...")
    es.indices.delete(index=index_name, ignore_unavailable=True)
    print(f"âœ… ì¸ë±ìŠ¤ '{index_name}' ì‚­ì œ ì™„ë£Œ.")

# âœ… Elasticsearch ë§¤í•‘ ì„¤ì • (Synonym ì—†ìŒ)
mapping = {
    "settings": {
        "analysis": {
            "analyzer": {
                "keyword_analyzer": {  # âœ… íšŒì‚¬ëª… ê²€ìƒ‰ìš© (ì •í™•í•œ ê²€ìƒ‰)
                    "tokenizer": "keyword"
                },
                "my_nori_analyzer": {  # âœ… ì—…ì¢… ë° ì£¼ìš” ì œí’ˆ ê²€ìƒ‰ìš© (í˜•íƒœì†Œ ë¶„ì„)
                    "tokenizer": "nori_tokenizer",
                    "char_filter": ["html_strip"],
                    "filter": ["nori_readingform", "lowercase"]
                }
            },
            "tokenizer": {
                "nori_tokenizer": {  # âœ… ì‚¬ìš©ì ì‚¬ì „ ì—†ì´ ê¸°ë³¸ í˜•íƒœì†Œ ë¶„ì„ê¸° ì ìš©
                    "type": "nori_tokenizer"
                }
            }
        }
    },
    "mappings": {
        "properties": {
            "stock_code": {"type": "keyword"},
            "company_name": {"type": "text", "analyzer": "keyword_analyzer", "boost": 3.0},  # âœ… íšŒì‚¬ëª… ê²€ìƒ‰ ê°€ì¤‘ì¹˜ 3.0
            "industry": {"type": "text", "analyzer": "my_nori_analyzer", "boost": 2.0},  # âœ… ì—…ì¢… ê²€ìƒ‰ ê°€ì¤‘ì¹˜ 2.0
            "main_products": {"type": "text", "analyzer": "my_nori_analyzer", "boost": 1.5},  # âœ… ì£¼ìš” ì œí’ˆ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ 1.5
            "listing_date": {"type": "date", "format": "yyyy-MM-dd"}
        }
    }
}

# âœ… ìƒˆë¡œìš´ ì¸ë±ìŠ¤ ìƒì„±
print(f"ğŸ“Œ ìƒˆë¡œìš´ ì¸ë±ìŠ¤ '{index_name}' ìƒì„± ì¤‘...")
es.indices.create(index=index_name, body=mapping, ignore=400)
print(f"âœ… ì¸ë±ìŠ¤ '{index_name}' ìƒì„± ì™„ë£Œ!")

# âœ… ë°ì´í„° Elasticsearchì— ì ì¬
actions = [
    {
        "_op_type": "index",
        "_index": index_name,
        "_source": row
    }
    for row in json_records
]

# âœ… Bulk API ì‹¤í–‰
success, failed = helpers.bulk(es, actions, refresh='wait_for', stats_only=True)


# âœ… ë°ì´í„°ê°€ ì •ìƒì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
count = es.count(index=index_name)['count']
print(f"âœ… ìµœì¢… ì €ì¥ëœ ë°ì´í„° ê°œìˆ˜: {count}ê°œ")

